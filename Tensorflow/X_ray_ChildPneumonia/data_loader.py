# å¯¼å…¥ç›¸å…³åº“
import cv2
import os
#os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
#os.environ["GRPC_VERBOSITY"] = "ERROR"

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
plt.rcParams['font.sans-serif'] = ['SimHei']  # ä½¿ç”¨å¾®è½¯é›…é»‘
plt.rcParams['axes.unicode_minus'] = False  # æ”¯æŒè´Ÿå·
# è¯»å–å›¾åƒ
import matplotlib.image as mpimg
# TensorFlow å’Œ Keras å±‚ã€æ¨¡å‹ã€ä¼˜åŒ–å’ŒæŸå¤±
import tensorflow as tf
from tensorflow import keras
from keras import Sequential
from keras.layers import * 
from tensorflow.keras.losses import BinaryCrossentropy # äºŒå…ƒäº¤å‰ç†µæŸå¤±å‡½æ•°
# åˆå§‹åŒ–å†…æ ¸ã€‚LabelEncoder å·¥å…·å°†å°†æ–‡æœ¬æ ‡ç­¾è½¬æ¢ä¸ºæ•°å€¼æ ‡ç­¾
from sklearn.preprocessing import LabelEncoder 
# è‡ªé€‚åº”çŸ©ä¼°è®¡ä¼˜åŒ–å™¨
from tensorflow.keras.optimizers import Adam , Adamax
# é¢„è®­ç»ƒæ¨¡å‹ Xception
from tensorflow.keras.applications import *
# æ—©åœå›è°ƒå‡½æ•°ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç›‘æ§éªŒè¯é›†çš„æ€§èƒ½ï¼Œå½“æ€§èƒ½ä¸å†æå‡æ—¶æå‰åœæ­¢è®­ç»ƒ
from tensorflow.keras.callbacks import EarlyStopping
import warnings 
warnings.filterwarnings("ignore")


USE_GPU = True 
if USE_GPU:
    gpus = tf.config.list_physical_devices('GPU')
    if gpus:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        print("âœ… GPU å¯ç”¨æˆåŠŸ:", gpus)
    else:
        print("âŒ æœªæ£€æµ‹åˆ° GPUï¼Œå°†ä½¿ç”¨ CPUã€‚")
else:
    os.environ["CUDA_VISIBLE_DEVICES"] = "-1"
    print("ğŸš« GPU è®¡ç®—å…³é—­ï¼Œä½¿ç”¨ CPUã€‚")


# æ•°æ®é›†è·¯å¾„
train_directory = "./data/train"
test_directory = "./data/test"
val_directory = "./data/val"

IMAGE_SIZE = (256, 256)

def load_data():
    print('-' * 20 + 'DATA LOADING' +'-' * 20)

    # éšæœºå±•ç¤ºéƒ¨åˆ†æ•°æ®
    show_data('TRAIN', train_directory)
    show_data('TEST', test_directory)

    print('-' * 20 + 'MAKE DATASETS' +'-' * 20)

    # è®­ç»ƒé›†
    print('TRAIN DATASET: ')
    train_ds = tf.keras.utils.image_dataset_from_directory(
        train_directory,
        validation_split=0.1,
        subset='training',
        seed=123,
        image_size=IMAGE_SIZE,
        batch_size=32
    )

    # éªŒè¯é›†
    print('VAL DATASET: ')
    validation_ds = tf.keras.utils.image_dataset_from_directory(
        train_directory,
        validation_split=0.1,
        subset='validation',
        seed=123,
        image_size=IMAGE_SIZE,
        batch_size=32
    )

    # æµ‹è¯•é›†
    print('TEST DATASET: ')
    test_ds = tf.keras.utils.image_dataset_from_directory(
        test_directory,
        seed=123,
        image_size=IMAGE_SIZE,
        batch_size=32
    )

    return train_ds, validation_ds, test_ds

def show_data(dataname, directory):
    filepath =[] # å­˜å‚¨å›¾åƒå­˜æ”¾è·¯å¾„
    label = [] # å­˜å‚¨å¯¹åº”æ ‡ç­¾

    folds = os.listdir(directory)

    for fold in folds:
        f_path = os.path.join(directory, fold)
        imgs = os.listdir(f_path)

        for img in imgs:
            img_path = os.path.join(f_path, img)
            filepath.append(img_path)
            label.append(fold)

    # é“¾æ¥æ•°æ®è·¯å¾„å’Œæ ‡ç­¾
    file_path_series = pd.Series(filepath, name='filepath')
    Label_path_series = pd.Series(label, name='label')
    df= pd.concat([file_path_series, Label_path_series], axis=1) 
    
    # æŸ¥çœ‹éƒ¨åˆ†æ•°æ®æƒ…å†µ
    print(f'{dataname} data:')
    print(df.sample(5))

# load_data()